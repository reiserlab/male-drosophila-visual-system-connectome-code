{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a37d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:36:12.938731Z",
     "iopub.status.busy": "2024-03-18T14:36:12.938401Z",
     "iopub.status.idle": "2024-03-18T14:36:25.563135Z",
     "shell.execute_reply": "2024-03-18T14:36:25.562322Z",
     "shell.execute_reply.started": "2024-03-18T14:36:12.938702Z"
    }
   },
   "outputs": [],
   "source": [
    "# from neuprint import Client\n",
    "\n",
    "# c = Client('https://neuprint-cns.janelia.org/', dataset='optic-lobe', token= TBD)\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = Path(find_dotenv()).parent\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT.joinpath('src')))\n",
    "print(f\"Project root directory: {PROJECT_ROOT}\")\n",
    "\n",
    "from utils import olc_client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7db2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:36:25.564804Z",
     "iopub.status.busy": "2024-03-18T14:36:25.564463Z",
     "iopub.status.idle": "2024-03-18T14:36:29.004749Z",
     "shell.execute_reply": "2024-03-18T14:36:29.004006Z",
     "shell.execute_reply.started": "2024-03-18T14:36:25.564783Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "\n",
    "from neuprint import fetch_synapses,NeuronCriteria as NC, SynapseCriteria as SC,merge_neuron_properties,IsNull, NotNull\n",
    "from neuprint.queries import fetch_synapse_connections,fetch_neurons, fetch_adjacencies,fetch_synapses\n",
    "from sklearn import decomposition\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "import fastcluster \n",
    "\n",
    "import plotly.express as px\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767a436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:36:29.006611Z",
     "iopub.status.busy": "2024-03-18T14:36:29.005992Z",
     "iopub.status.idle": "2024-03-18T14:36:29.142232Z",
     "shell.execute_reply": "2024-03-18T14:36:29.141378Z",
     "shell.execute_reply.started": "2024-03-18T14:36:29.006587Z"
    }
   },
   "outputs": [],
   "source": [
    "c = olc_client.connect(verbose=True)\n",
    "\n",
    "data_dir = PROJECT_ROOT / \"results\" / \"clustering\"\n",
    "cache_dir = PROJECT_ROOT / \"cache\" / \"clustering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72298a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.clustering_functions import remove_brackets, make_in_and_output_df, get_row_linkage, cluster_dict_from_linkage, set_annotations, make_count_table, cluster_with_type_names, format_list, set_pca_for_projections, get_combined_synapses_with_stdev, remove_R_or_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d74ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:38:50.796582Z",
     "iopub.status.busy": "2024-03-18T14:38:50.796213Z",
     "iopub.status.idle": "2024-03-18T14:39:56.920080Z",
     "shell.execute_reply": "2024-03-18T14:39:56.919270Z",
     "shell.execute_reply.started": "2024-03-18T14:38:50.796557Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a directionary of bodyIds->cell types\n",
    "# neuprint only version (i.e. no additional external annotations\n",
    "\n",
    "# named optic lobe neurons from neuprint\n",
    "criteria = NC(type=NotNull, rois=['ME(R)', 'LO(R)', 'LOP(R)','AME(R)','LA(R)'], roi_req='any')\n",
    "named_neurons, _ = fetch_neurons(criteria)\n",
    "\n",
    "#  dictionary bodyId:type\n",
    "bodyId_type = dict(zip(list(named_neurons.bodyId.astype(int)),list(named_neurons.type)))\n",
    "\n",
    "# list of  named cell types with arbors in both OL (i.e.a left and right instance in the dataset)\n",
    "# purpose is to treat L and R instances a different types for clustering purposes\n",
    "named_neurons['LR']=named_neurons.instance\n",
    "named_neurons['LR']=named_neurons['LR'].apply(lambda x: x[-2:])  # assumes instances ending with '_L'or '_R'\n",
    "LR_count = named_neurons.groupby(by=['type','LR'],as_index=False).count().groupby(by='type').count()\n",
    "bilateral_cell_types = LR_count [LR_count ['LR']==2].index.tolist()\n",
    "\n",
    "\n",
    "# dictionary of bodyId:instance for instances of bilateral types\n",
    "bilateral_cells_bodyId_instance = dict(zip(named_neurons[named_neurons['type'].isin(bilateral_cell_types)].bodyId.tolist(),named_neurons[named_neurons['type'].isin(bilateral_cell_types)].instance.tolist()))\n",
    "\n",
    "#bodies with named instances without a type name (fragments have an instance but not a type name)\n",
    "\n",
    "criteria = NC(instance=NotNull, rois=['ME(R)', 'LO(R)', 'LOP(R)','AME(R)','LA(R)'], roi_req='any')\n",
    "named_instances, _ = fetch_neurons(criteria)\n",
    "named_instances= (named_instances[((named_instances['type']!= named_instances['type'])|\n",
    "                                   (named_instances['type']==''))])   #. type either None or empty string\n",
    "## named_instances.instance= named_instances.instance.apply(remove_brackets)  ##not needed?\n",
    "\n",
    "named_instances.instance= named_instances.instance.apply(remove_R_or_L)\n",
    "\n",
    "#   dictionary bodyId:instance for EM bodies without a type \n",
    "bodyId_instance = dict(zip(list(named_instances.bodyId.astype(int)),list(named_instances.instance)))\n",
    "\n",
    "# combine dictionaries:\n",
    "# replace entries for bilateral cells with bilateral_cells_bodyId_instance\n",
    "bodyId_type = { **bodyId_type,**bilateral_cells_bodyId_instance} \n",
    "## add instances\n",
    "bodyId_type = { **bodyId_instance,**bodyId_type}  ## instances don't overwrite what is already in dictionary\n",
    "\n",
    "# remove None types (should not be needed anymore)\n",
    "bodyId_type = {k: v for k, v in bodyId_type.items() if v is not None}  \n",
    "\n",
    "## known false merges (dictionary) (only needed for versions used during proofreading stage)\n",
    "false_merges_dict ={}\n",
    "\n",
    "## types names in 'exclude from clustering' are not used for clustering\n",
    "## in this version all cells with 'unclear' in name are not used for clustering\n",
    "exclude_from_clustering =[x for x in list(set(bodyId_type.values())) if 'unclear' in x]\n",
    "exclude_from_clustering =exclude_from_clustering +['(Lamina_TBD']  # temporary fix, remove later\n",
    "\n",
    "# list of all unique names in use\n",
    "type_and_instance_names = set(list (bodyId_type.values()))  \n",
    "\n",
    "# dictionay of names to be changed when generating connectivity table for clustering\n",
    "# here used to identify 'fragments' to be combined with tge corresponding types\n",
    "\n",
    "names_with_fragment = [x for x in type_and_instance_names if 'fragment' in x]\n",
    "fragment_type_dict = dict(zip(names_with_fragment,[x.split('_fragment')[0] for x in names_with_fragment]))\n",
    "fragment_type_dict = {bodyId: name  for bodyId, name in fragment_type_dict.items()} \n",
    "\n",
    "\n",
    "\n",
    "# summary\n",
    "names_with_unclear = [x for x in type_and_instance_names if 'unclear' in x]\n",
    "names_with_fragment = [x for x in type_and_instance_names if 'fragment' in x]\n",
    "print ('total cells', len(bodyId_type))\n",
    "print ('total instance only names', len(bodyId_instance))\n",
    "print ('total instance types', len(list(set(list (bodyId_instance.values())))))\n",
    "print('all names in use', len(type_and_instance_names))\n",
    "print('fragment names', len(names_with_fragment))\n",
    "print('\"unclear\" names', len(names_with_unclear))\n",
    "print('bilateral_types', len(bilateral_cell_types))\n",
    "print('cell types', (len(type_and_instance_names)-len(names_with_fragment)\n",
    "                     -len(names_with_unclear)-len(bilateral_cell_types)))\n",
    "\n",
    "fragment_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a86c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of bodyIds to cluster (here: based on region and synapse numbers and whether the body has type or instance name)\n",
    "\n",
    "criteria = NC(rois=['ME(R)', 'LO(R)', 'LOP(R)','AME(R)','LA(R)'], roi_req='any')\n",
    "neurons_all, _ = fetch_neurons(criteria)\n",
    "neurons_all = neurons_all[neurons_all.synweight > 100]  ## the >100 threshold is ok for most OL cells except a few near the edges\n",
    "\n",
    "neuron_selection= list(set(neurons_all.bodyId.tolist()+list(bodyId_type.keys())))  \n",
    "len(neuron_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611686cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get up- and downstream synaptic partners of all bodies in neuron_selection\n",
    "\n",
    "cache_target_fn = cache_dir / \"ROL_targets_df_neuprint_only_102023.pickle\"\n",
    "\n",
    "if cache_target_fn.is_file():\n",
    "    ## load dataframes with connection data (faster than getting these from neuprint \n",
    "    ## and soon no further changes will be expected for the right optic lobe for now)\n",
    "    conn_df_targets = pd.read_pickle(cache_target_fn)\n",
    "else:\n",
    "    criteria = NC(bodyId=neuron_selection)\n",
    "    neuron_df1, conn_df1 = fetch_adjacencies(criteria,None,include_nonprimary=False) # targets\n",
    "    conn_df_targets = merge_neuron_properties(neuron_df1, conn_df1)\n",
    "    del neuron_df1, conn_df1\n",
    "    ## save dataframes with connection data (reload is faster than getting these from neuprint)\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    conn_df_targets.to_pickle(cache_target_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e838934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_input_fn  = cache_dir / \"ROL_inputs_df_neuprint_only_102023.pickle\"\n",
    "\n",
    "if cache_input_fn.is_file():\n",
    "    ## load dataframes with connection data (faster than getting these from neuprint \n",
    "    ## and soon no further changes will be expected for the right optic lobe for now)\n",
    "    conn_df_inputs = pd.read_pickle(cache_input_fn)\n",
    "else:\n",
    "    criteria = NC(bodyId=neuron_selection)\n",
    "    neuron_df2, conn_df2 = fetch_adjacencies(None,criteria,include_nonprimary=False) # inputs\n",
    "    conn_df_inputs = merge_neuron_properties(neuron_df2, conn_df2)\n",
    "    del neuron_df2, conn_df2\n",
    "    ## save dataframes with connection data (reload is faster than getting these from neuprint)\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    conn_df_inputs.to_pickle(cache_input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a34951",
   "metadata": {},
   "outputs": [],
   "source": [
    "### clustering a subset of neurons\n",
    "### to run this for the full optic lobe set cell_list=neuron_selection (see above) and number_of_clusters to e.g. 600\n",
    "\n",
    "### example: clusters MeTu4 cells and makes a table with the counts for each type in each cluster\n",
    "\n",
    "\n",
    "## generate a list of bodyIds to cluster; for reclustering use clusters_bodyIds[] as input\n",
    "type_selection = (list(set([cell_type for cell_type in bodyId_type.values() if (cell_type.startswith('MeTu4')) ])))\n",
    "#type_selection =['LT51','LC33']\n",
    "\n",
    "\n",
    "cell_list = [bodyId for bodyId in bodyId_type.keys() if  bodyId_type[bodyId] in type_selection]\n",
    "\n",
    "## make connection table \n",
    "types_to_exclude= ( exclude_from_clustering)   # option to exclude cell types\n",
    "named_types_for_clustering =[] # option to only use connections to selected types\n",
    " \n",
    "connection_table =  (make_in_and_output_df(conn_df_inputs,conn_df_targets,bodyId_type,\n",
    "                           types_to_exclude=types_to_exclude,\n",
    "                           fragment_type_dict=fragment_type_dict,\n",
    "                           bodyIds_to_use = cell_list))\n",
    "\n",
    "# clustering:  produces dicitionaries of the bodyIds in each cluster, the types for each bodyId in a cluster \n",
    "# and the cluster it is in for each bodyIs\n",
    "\n",
    "number_of_clusters = len(type_selection)-1  #-1 added in this case because MeTu4_unclear is not a separate type\n",
    "\n",
    "row_linkage = get_row_linkage (connection_table,metric='cosine',linkage_method = 'ward',optimal_ordering=False)\n",
    "clusters_bodyIds = cluster_dict_from_linkage (row_linkage,connection_table,t=number_of_clusters,criterion = 'maxclust')\n",
    "clusters_cell_types = cluster_with_type_names(clusters_bodyIds,bodyId_type)\n",
    "\n",
    "    \n",
    "bodyIds_clusters =  {bodyId:cluster for cluster in clusters_bodyIds.keys() for bodyId in clusters_bodyIds[cluster]}\n",
    "\n",
    "# table with results\n",
    "cells_per_cluster_by_type = make_count_table (clusters_cell_types)\n",
    "cells_per_cluster_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74394231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: bodyIds in a specific cluster\n",
    "\n",
    "format_list(clusters_bodyIds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48110068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: cell_types in a specific cluster\n",
    "\n",
    "format_list(clusters_cell_types[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## The code below illustrates splitting cell types (or groups of cell types) into two groups and displaying the result\n",
    "## as a map of cell locations (as mean synapse locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## provides coordinate systems for plotting neuron postions in the main OL regions\n",
    "\n",
    "\n",
    "pca_medulla= set_pca_for_projections (cell_type_pre = ['Mi1','Tm1'],cell_type_post = 'Pm2a')\n",
    "\n",
    "pca_lobula = set_pca_for_projections (cell_type_pre = ['Tm5a','Tm5b-1'],cell_type_post = ['LC6','LC10c','LC16'],\n",
    "                                     neuropile_region = 'LO(R)')\n",
    "\n",
    "\n",
    "pca_lobula_plate = set_pca_for_projections (cell_type_pre = ['T4b','T5b'],cell_type_post = 'H2',neuropile_region = 'LOP(R)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example: \n",
    "\n",
    "pca=pca_medulla  ##select  as appropriate for a  cell type\n",
    "rois = ['ME(R)']\n",
    "#rois = ['LO(R)']  \n",
    "#pca=pca_lobula\n",
    "#rois = ['LOP(R)'] \n",
    "#pca=pca_lobula_plate\n",
    "\n",
    "type_names=['Tm5b']  ## cell type(s) to be subdivided\n",
    "type_name='Tm5b'  # name to use for the group in output files\n",
    "\n",
    "type_selection = (list(set([cell_type for cell_type in bodyId_type.values() if (cell_type in type_names) ])))\n",
    "cell_list = [bodyId for bodyId in bodyId_type.keys() if  bodyId_type[bodyId] in type_selection]\n",
    "\n",
    "total_cells = len(cell_list)\n",
    "types_to_exclude= ( exclude_from_clustering)\n",
    "\n",
    "\n",
    "connection_table =  (make_in_and_output_df(conn_df_inputs,conn_df_targets,bodyId_type,\n",
    "                           types_to_exclude=types_to_exclude,\n",
    "                           fragment_type_dict=fragment_type_dict,\n",
    "                           bodyIds_to_use = cell_list))\n",
    "\n",
    "number_of_clusters = 2\n",
    "row_linkage = get_row_linkage (connection_table,metric='cosine',linkage_method = 'ward',optimal_ordering=False)\n",
    "clusters_bodyIds = cluster_dict_from_linkage (row_linkage,connection_table,t=number_of_clusters,criterion = 'maxclust')\n",
    "clusters_cell_types = cluster_with_type_names(clusters_bodyIds,bodyId_type)\n",
    "\n",
    "total_cells = len(cell_list)\n",
    "\n",
    "cells_per_cluster_by_type = make_count_table (clusters_cell_types)\n",
    "print(cells_per_cluster_by_type)\n",
    "\n",
    "cell_list1=clusters_bodyIds[1]\n",
    "\n",
    "bodyIds_to_exclude = []  #list of relevant false merges\n",
    "neuron_criteria = NC(bodyId=cell_list1)\n",
    "synapse_criteria = SC(rois=rois, primary_only=False)\n",
    "\n",
    "combined_synapses =get_combined_synapses_with_stdev(neuron_criteria,synapse_criteria,\n",
    "                                                       bodyIds_to_exclude=bodyIds_to_exclude,rois=['LO(R)'],pca=pca)\n",
    "\n",
    "cell_list2=clusters_bodyIds[2]\n",
    "neuron_criteria = NC(bodyId=cell_list2)\n",
    "combined_synapses2 =get_combined_synapses_with_stdev(neuron_criteria,synapse_criteria,\n",
    "                                                       bodyIds_to_exclude=bodyIds_to_exclude,rois=['LO(R)'],pca=pca)\n",
    "\n",
    "combined_synapses['type']=type_name+\"-1\"\n",
    "combined_synapses2['type']=type_name+\"-2\"\n",
    "synapses_for_plotting = pd.concat([combined_synapses,combined_synapses2])\n",
    "synapses_for_plotting_2=synapses_for_plotting.copy()\n",
    "synapses_for_plotting_2['type']=[type_name]*len(synapses_for_plotting_2)\n",
    "synapses_for_plotting_2['facet']=['all']*len(synapses_for_plotting_2)\n",
    "synapses_for_plotting['facet']=[type_name+' split']*len(synapses_for_plotting)\n",
    "\n",
    "synapses_for_plotting = pd.concat([synapses_for_plotting_2,synapses_for_plotting])\n",
    "#synapses_for_plotting.to_csv(directory+\"synapses_for_subtype_plots/\"+type_name+\".csv\")\n",
    "                             \n",
    "fig = px.scatter(synapses_for_plotting, x=\"X\", y=\"Y\", marginal_y=None,marginal_x=None,color='type',\n",
    "                 hover_data=['bodyId','weight'],color_discrete_sequence=[\"blue\", \"red\", \"blue\"], facet_col=\"facet\")\n",
    "    \n",
    "fig.add_annotation(\n",
    "    text=cells_per_cluster_by_type.to_string().replace('\\n','<br>'), \n",
    "    align='left',\n",
    "    showarrow=False,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    x=1.135,\n",
    "    y=0.6,\n",
    "    bordercolor='black',\n",
    "    borderwidth=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6784181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split a series of cell types or cell type groups and save the results\n",
    "## for \n",
    "\n",
    "type_names_types =[\n",
    "    (['Tm5b-1','Tm5b-2'],'Tm5b',['ME(R)'] ),\n",
    "    (['LPi34','LPi43'],'LPI34_LPi43',['LOP(R)'] ),\n",
    "    (['LLPC1','LLPC2'],'LLPC1_LLPC2',['LOP(R)'] ),\n",
    "    (['Li14','Li22'],'Li14_Li22',['LO(R)'] ),\n",
    "    (['Pm2a','Pm2b'],'Pm2' ,['ME(R)']),\n",
    "    (['LC10a','LC10a'],'LC10a',['LO(R)']),\n",
    "    (['LC9'],'LC9', ['LO(R)']),\n",
    "    (['LC6'],'LC6', ['LO(R)']),\n",
    "    (['LC4'],'LC4', ['LO(R)']),\n",
    "    (['LC11'],'LC11', ['LO(R)']),\n",
    "    (['LC12'],'LC12', ['LO(R)']),\n",
    "    (['Tm5b-1','Tm5b-2'],'Tm5b',['ME(R)'] ),\n",
    "    (['Tm5a','Tm5b-1'],'Tm5ab',['ME(R)'] ),\n",
    "    (['TmY9a','TmY9b'],'TmY9',['ME(R)'] ),\n",
    "    (['Dm3a-1','Dm3a-2'],'Dm3a',['ME(R)'] ),\n",
    "    (['Mti18a','Mti18b'],'Mti18ab',['ME(R)'] ),\n",
    "    (['Pm5','Pm6'],'Pm5_Pm6',['ME(R)'] ),\n",
    "    (['Mi10'],'Mi10',['ME(R)'] ),\n",
    "    (['LC17'],'LC17', ['LO(R)'])\n",
    "]\n",
    "\n",
    "for type_names,type_name, rois in type_names_types:\n",
    "    \n",
    "    if rois==['ME(R)']:\n",
    "        pca=pca_medulla\n",
    "    elif rois==['LO(R)']:\n",
    "        pca=pca_lobula\n",
    "    else:\n",
    "        pca=pca_lobula_plate\n",
    "        \n",
    "    type_selection = (list(set([cell_type for cell_type in bodyId_type.values() if (cell_type in type_names)])))\n",
    "    cell_list = [bodyId for bodyId in bodyId_type.keys() if  bodyId_type[bodyId] in type_selection]\n",
    "\n",
    "    total_cells = len(cell_list)\n",
    "    types_to_exclude= (exclude_from_clustering)\n",
    "\n",
    "\n",
    "    connection_table = (\n",
    "        make_in_and_output_df(\n",
    "            conn_df_inputs,\n",
    "            conn_df_targets,\n",
    "            bodyId_type,\n",
    "            types_to_exclude=types_to_exclude,\n",
    "            fragment_type_dict=fragment_type_dict,\n",
    "            bodyIds_to_use = cell_list))\n",
    "\n",
    "    number_of_clusters = 2\n",
    "    row_linkage = get_row_linkage(\n",
    "        connection_table,\n",
    "        metric='cosine',\n",
    "        linkage_method='ward',\n",
    "        optimal_ordering=False)\n",
    "    \n",
    "    clusters_bodyIds = cluster_dict_from_linkage(\n",
    "        row_linkage,\n",
    "        connection_table,\n",
    "        t=number_of_clusters,\n",
    "        criterion = 'maxclust')\n",
    "    clusters_cell_types = cluster_with_type_names(\n",
    "        clusters_bodyIds,\n",
    "        bodyId_type)\n",
    "\n",
    "    total_cells = len(cell_list)\n",
    "\n",
    "    cells_per_cluster_by_type = make_count_table (clusters_cell_types)\n",
    "    print(cells_per_cluster_by_type)\n",
    "\n",
    "    cell_list1=clusters_bodyIds[1]\n",
    "\n",
    "    bodyIds_to_exclude = []  #list of relevant false merges\n",
    "    neuron_criteria = NC(bodyId=cell_list1)\n",
    "    synapse_criteria = SC(rois=rois, primary_only=False)\n",
    "\n",
    "    combined_synapses =get_combined_synapses_with_stdev(\n",
    "        neuron_criteria,\n",
    "        synapse_criteria,\n",
    "        bodyIds_to_exclude=bodyIds_to_exclude,\n",
    "        rois=['LO(R)'])\n",
    "\n",
    "    cell_list2=clusters_bodyIds[2]\n",
    "    neuron_criteria = NC(bodyId=cell_list2)\n",
    "    combined_synapses2 = get_combined_synapses_with_stdev(\n",
    "        neuron_criteria,\n",
    "        synapse_criteria,\n",
    "        bodyIds_to_exclude=bodyIds_to_exclude,\n",
    "        rois=['LO(R)'])\n",
    "\n",
    "    combined_synapses['type']=type_name+\"-1\"\n",
    "    combined_synapses2['type']=type_name+\"-2\"\n",
    "    synapses_for_plotting = pd.concat([combined_synapses,combined_synapses2])\n",
    "    synapses_for_plotting_2=synapses_for_plotting.copy()\n",
    "    synapses_for_plotting_2['type']=[type_name]*len(synapses_for_plotting_2)\n",
    "    synapses_for_plotting_2['facet']=['all']*len(synapses_for_plotting_2)\n",
    "    synapses_for_plotting['facet']=[type_name+' split']*len(synapses_for_plotting)\n",
    "\n",
    "    synapses_for_plotting = pd.concat([synapses_for_plotting_2,synapses_for_plotting])\n",
    "    #synapses_for_plotting.to_csv(directory+\"synapses_for_subtype_plots/\"+type_name+\".csv\") \n",
    "                             \n",
    "    fig = px.scatter(\n",
    "        synapses_for_plotting, \n",
    "        x=\"X\", y=\"Y\", \n",
    "        marginal_y=None,\n",
    "        marginal_x=None,\n",
    "        color='type',\n",
    "        hover_data=['bodyId','weight'],\n",
    "        color_discrete_sequence=[\"blue\", \"red\", \"blue\"], \n",
    "        facet_col=\"facet\")\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=cells_per_cluster_by_type.to_string().replace('\\n','<br>'), \n",
    "        align='left',\n",
    "        showarrow=False,\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        x=1.135,\n",
    "        y=0.6,\n",
    "        bordercolor='black',\n",
    "        borderwidth=1)\n",
    "    fig.show()\n",
    "    \n",
    "    ## saving figures as .html version (interactive) and pdfs\n",
    "    output_dir = data_dir / \"subtypes_plots\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    fig.write_html(output_dir / f\"{type_name}_101923.html\")\n",
    "    fig.write_image(output_dir / f\"{type_name}_101923.pdf\", width=1080, height=540)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34f0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "93c03c68f817c0f41fa4fec56e138bf7e0333691aa85da563a4ad01a3e7c4aa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
